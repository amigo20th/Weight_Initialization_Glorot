# Weight Initialization with Glorot

In this notebook we will see how works the weights initialization in Artificial Neural Network, we will how we can avoid a saturation in the neurons.

The neuron saturation is a problem that affect Artifical Neural Network (ANN) beacause in neurons with sigmoid activation delay the learning of the network. That it to say, an ANN with sigmoid activation has problems with backpropagation that happends for weghts very big.

In this demostration we will see how it is the distribution in a layer after we let's initialize the weights with a Gaussian distribution. Later we will se how it is the distribution in a layer with a Glorot distribution.
