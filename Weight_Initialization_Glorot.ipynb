{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weight_Initialization_Glorot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crdzg6Jiu3k5",
        "colab_type": "text"
      },
      "source": [
        "<h1>Weight Initialization.</h1>\n",
        "\n",
        "In this notebook we will see how works the weights initialization in Artificial Neural Network, we will how we can avoid a saturation in the neurons.\n",
        "\n",
        "The neuron saturation is a problem that affect Artifical Neural Network (ANN) beacause in neurons with sigmoid activation delay the learning of the network. That it to say, an ANN with sigmoid activation has problems with backpropagation that happends for weghts very big.\n",
        "\n",
        "In this demostration we will see how it is the distribution in a layer after we let's initialize the weights with a Gaussian distribution. Later we will se how it is the distribution in a layer with a Glorot distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5P3Omrcypvs",
        "colab_type": "text"
      },
      "source": [
        "First, declare libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A21mSlkIym0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7f2ecd9-aa0e-44e9-ae3f-cc326421c44e"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.initializers import Zeros, RandomNormal, glorot_normal, glorot_uniform"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAweULKizqB6",
        "colab_type": "text"
      },
      "source": [
        "In this experiment we will create one observation with 784 inputs, that because it is 784 that represent the pixels in the MNIST dataset*. Also we will create a layer with 256 neurons.\n",
        "\n",
        "*http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXhoUs4Pzj8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_input = 784\n",
        "n_dense=256\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSZvVmxB1I3m",
        "colab_type": "text"
      },
      "source": [
        "For is common practice, we initialize the *bias* with zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sUtZPcb0d2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_init = Zeros()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCBHgwTB2M2h",
        "colab_type": "text"
      },
      "source": [
        "So, we initialize the weights with a normal distribution, this distribution has a mean in 0 and standard deviation is 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du2y_a4QBwQF",
        "colab_type": "text"
      },
      "source": [
        "***We need to have Normal initialization enabled and Glorot commented out, unless otherwise specified.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgIpt-fW1TVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# w_init = RandomNormal(stddev = 1.0)\n",
        "# w_init = glorot_normal()\n",
        "w_init = glorot_uniform()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY13jQsL2iUG",
        "colab_type": "text"
      },
      "source": [
        "We create the Artificial Neural Network with sigmoid activation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI3-Phz72Vf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(n_dense,\n",
        "                input_dim=n_input,\n",
        "                kernel_initializer=w_init,\n",
        "                bias_initializer=b_init))\n",
        "model.add(Activation('sigmoid'))\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTzHouC63Y1y",
        "colab_type": "text"
      },
      "source": [
        "We create a data dummy because it doesn't matter the input for the demonstration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTccUjXa2fMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93688c39-7dfb-4187-9218-c43b7de3f064"
      },
      "source": [
        "x = np.random.random((1, n_input))\n",
        "x.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3BHyYt_32wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we apply x in ANN\n",
        "a = model.predict(x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjGm3iK44EUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "1f73d766-ac00-4b4a-c6a1-3207d61a6e69"
      },
      "source": [
        "#We graphic for to see the new data.\n",
        "plt.hist(np.transpose(a))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1., 13., 29., 32., 39., 44., 41., 32., 21.,  4.]),\n",
              " array([0.09190032, 0.16975392, 0.24760754, 0.32546115, 0.40331477,\n",
              "        0.4811684 , 0.559022  , 0.63687557, 0.7147292 , 0.7925828 ,\n",
              "        0.87043643], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2_WZbz87t5l",
        "colab_type": "text"
      },
      "source": [
        "How we can see in this new data mostly of them lives in zero or one, that is a problem because that cause neuron saturation, on the supposed we have another layers after the one we have.\n",
        "\n",
        "Now we will see how it is the tranformation with Glorot distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWoWigrJAR2d",
        "colab_type": "text"
      },
      "source": [
        "Before everything, we need to restart and rerunning the notebook, it is important that this way it takes the new initial weights.\n",
        "We need change the new weights in the ANN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9TRgIBc8g7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# go to the weights initialization section, then comment the normal initialization and put on the Glorot\n",
        "# w_init = glorot_normal= ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y320p1XC0w1",
        "colab_type": "text"
      },
      "source": [
        "#Conclusions\n",
        "We see how a Glorot distribution, whether normal or uniform, helps to avoid saturation of neurons since it maintain the weights near of zero.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdndkB8HDmzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}